{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de7db5ae",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4af81300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "import statsmodels.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46fc6726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34138 entries, 0 to 34137\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   book            34138 non-null  object\n",
      " 1   author          34138 non-null  object\n",
      " 2   rating_count    34138 non-null  int64 \n",
      " 3   is_volume       34138 non-null  object\n",
      " 4   author_sex      34138 non-null  object\n",
      " 5   author_exp      34138 non-null  object\n",
      " 6   book_size       34138 non-null  object\n",
      " 7   genre_category  34138 non-null  object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\juhic\\\\OneDrive\\\\Desktop\\\\master_dataset.csv')\n",
    "drop_cols = ['Unnamed: 0','author_avg_rating','author_work_count','log2_author_work_count','page_count','genre']\n",
    "data.drop(axis = 1, columns = drop_cols, inplace = True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6019417e",
   "metadata": {},
   "source": [
    "#### Type Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "064a9c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34138 entries, 0 to 34137\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   book            34138 non-null  object  \n",
      " 1   author          34138 non-null  object  \n",
      " 2   rating_count    34138 non-null  int64   \n",
      " 3   is_volume       34138 non-null  category\n",
      " 4   author_sex      34138 non-null  category\n",
      " 5   author_exp      34138 non-null  category\n",
      " 6   book_size       34138 non-null  category\n",
      " 7   genre_category  34138 non-null  category\n",
      "dtypes: category(5), int64(1), object(2)\n",
      "memory usage: 967.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data = data.astype({'is_volume':'category',\n",
    "                    'author_sex':'category',\n",
    "                    'author_exp':'category',\n",
    "                    'book_size':'category',\n",
    "                    'genre_category':'category'})\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3715ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>author</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>is_volume</th>\n",
       "      <th>author_sex</th>\n",
       "      <th>author_exp</th>\n",
       "      <th>book_size</th>\n",
       "      <th>genre_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inner circle</td>\n",
       "      <td>kate brian</td>\n",
       "      <td>7597</td>\n",
       "      <td>yes</td>\n",
       "      <td>female</td>\n",
       "      <td>average</td>\n",
       "      <td>average</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ambition</td>\n",
       "      <td>kate brian</td>\n",
       "      <td>6719</td>\n",
       "      <td>yes</td>\n",
       "      <td>female</td>\n",
       "      <td>average</td>\n",
       "      <td>average</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>revelation</td>\n",
       "      <td>kate brian</td>\n",
       "      <td>7431</td>\n",
       "      <td>yes</td>\n",
       "      <td>female</td>\n",
       "      <td>average</td>\n",
       "      <td>average</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>legacy</td>\n",
       "      <td>kate brian</td>\n",
       "      <td>7010</td>\n",
       "      <td>yes</td>\n",
       "      <td>female</td>\n",
       "      <td>average</td>\n",
       "      <td>average</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vanished</td>\n",
       "      <td>kate brian</td>\n",
       "      <td>3724</td>\n",
       "      <td>yes</td>\n",
       "      <td>female</td>\n",
       "      <td>average</td>\n",
       "      <td>average</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           book      author  rating_count is_volume author_sex author_exp  \\\n",
       "0  inner circle  kate brian          7597       yes     female    average   \n",
       "1      ambition  kate brian          6719       yes     female    average   \n",
       "2    revelation  kate brian          7431       yes     female    average   \n",
       "3        legacy  kate brian          7010       yes     female    average   \n",
       "4      vanished  kate brian          3724       yes     female    average   \n",
       "\n",
       "  book_size genre_category  \n",
       "0   average        fiction  \n",
       "1   average        fiction  \n",
       "2   average        fiction  \n",
       "3   average        fiction  \n",
       "4   average        fiction  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a48265c",
   "metadata": {},
   "source": [
    "#### Hypothesis 1:\n",
    "\n",
    "The publisher is interested to understand if the rating count between male & female authors is significantly different. If so, books from the group that holds larger rating counts would be prioritized over the other.\n",
    "\n",
    "<center> Null Hypothesis: Average rating counts b/w male & female authors are equal </center>\n",
    "<center> $mu_{male} = mu_{female} $\n",
    "\n",
    "Test:<br></br>\n",
    "Independent 2-tailed Un-equal variance Z-test to compare mean reader count among the 2 groups.\n",
    "\n",
    "\n",
    "Outcome:<br></br>\n",
    "p-value of the sample under Null Hypothesis  <br></br>\n",
    "Considering 5% level of significance,  if the p-value would be less than 5%, then we would reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c9e9926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>author_sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>7329.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a. kirk</td>\n",
       "      <td>5272.666667</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a. manette ansay</td>\n",
       "      <td>14418.000000</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a. meredith walters</td>\n",
       "      <td>13256.500000</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a. merritt</td>\n",
       "      <td>864.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author  rating_count author_sex\n",
       "0              50 cent   7329.000000       male\n",
       "1              a. kirk   5272.666667     female\n",
       "2     a. manette ansay  14418.000000     female\n",
       "3  a. meredith walters  13256.500000     female\n",
       "4           a. merritt    864.000000       male"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d0 = data.groupby(by = 'author').agg({'rating_count':'mean'}).reset_index()\n",
    "\n",
    "d1 = data[['author','author_sex']].drop_duplicates()\n",
    "d11 = pd.merge(d0, d1, on = 'author', how = 'inner')\n",
    "\n",
    "d11.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8215979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24638958656882956, 0.805380666531034)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats import weightstats as ws\n",
    "ws.ztest(x1 = d11.loc[d11['author_sex'] == 'male','rating_count'],\n",
    "         x2 = d11.loc[d11['author_sex'] == 'female', 'rating_count'],\n",
    "         value = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0738caca",
   "metadata": {},
   "source": [
    "#### Hypothesis 2\n",
    "\n",
    "The publisher is interested to know if new-comer authors (published < 16 books) have a similar rating count as an average author (published average #books). This is to help avoid the new-comer trap! (when a publisher discards the book solely reasoning that the author has no experience) <br></br>\n",
    "Work_count provides the #works (books, articles, revisions etc) of an author. It can be classified into 3 bins: \n",
    "- New-comers: <16 (or <2 std dev from mean) \n",
    "- Average: within 1 std. Dev from mean (both sides)\n",
    "- Legendary: > 1 std. Dev from mean\n",
    "\n",
    "<center> Null Hypothesis: Average rating count of a new-comer author is equal to that of an average author. </center>\n",
    "\n",
    "Test: <br></br>\n",
    "Independent 2-tailed Z-test to compare mean rating count b/w New-comers and Average authors.\n",
    "\n",
    "Outcome: <br></br>\n",
    "p-value of the sample under Null Hypothesis \\<br></br>\n",
    "Considering 5% level of significance,  if the p-value would be less than 5%, then we would reject the null hypothesis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4150804d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>author_exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>7329.000000</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a. kirk</td>\n",
       "      <td>5272.666667</td>\n",
       "      <td>newbie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a. manette ansay</td>\n",
       "      <td>14418.000000</td>\n",
       "      <td>newbie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a. meredith walters</td>\n",
       "      <td>13256.500000</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a. merritt</td>\n",
       "      <td>864.000000</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author  rating_count author_exp\n",
       "0              50 cent   7329.000000    average\n",
       "1              a. kirk   5272.666667     newbie\n",
       "2     a. manette ansay  14418.000000     newbie\n",
       "3  a. meredith walters  13256.500000    average\n",
       "4           a. merritt    864.000000    average"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = data[['author','author_exp']].drop_duplicates()\n",
    "d22 = pd.merge(d0, d2, on = 'author', how = 'inner')\n",
    "\n",
    "d22.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3be6f759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0160269164120113, 0.3096165691549334)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats import weightstats as ws\n",
    "ws.ztest(x1 = d22.loc[d22['author_exp'] == 'newbie','rating_count'],\n",
    "         x2 = d22.loc[d22['author_exp'] == 'average', 'rating_count'],\n",
    "         value = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e979e0d0",
   "metadata": {},
   "source": [
    "#### Grouping Hypothesis 1 & 2: It can also make sense to view the effect of author gender with author’s work exp (clubbing Hypothesis 1 & 2) on average rating count. We are not sure how it will play; so if there is insight - we would want to share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "842499f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>author_sex</th>\n",
       "      <th>author_exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50 cent</td>\n",
       "      <td>7329.000000</td>\n",
       "      <td>male</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a. kirk</td>\n",
       "      <td>5272.666667</td>\n",
       "      <td>female</td>\n",
       "      <td>newbie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a. manette ansay</td>\n",
       "      <td>14418.000000</td>\n",
       "      <td>female</td>\n",
       "      <td>newbie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a. meredith walters</td>\n",
       "      <td>13256.500000</td>\n",
       "      <td>female</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a. merritt</td>\n",
       "      <td>864.000000</td>\n",
       "      <td>male</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author  rating_count author_sex author_exp\n",
       "0              50 cent   7329.000000       male    average\n",
       "1              a. kirk   5272.666667     female     newbie\n",
       "2     a. manette ansay  14418.000000     female     newbie\n",
       "3  a. meredith walters  13256.500000     female    average\n",
       "4           a. merritt    864.000000       male    average"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3 = pd.merge(d11, d2, on = 'author', how = 'inner')\n",
    "d3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99f280c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.17405146915844733, 0.8618250129469954)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Male (Newbie v/s Average)\n",
    "from statsmodels.stats import weightstats as ws\n",
    "ws.ztest(x1 = d3.loc[(d3['author_sex'] == 'male') & (d3['author_exp'] == 'newbie'),'rating_count'],\n",
    "         x2 = d3.loc[(d3['author_sex'] == 'male') & (d3['author_exp'] == 'average'),'rating_count'],\n",
    "         value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce50117f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.629932952819773, 0.00028349484825117516)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Male (Newbie v/s Experienced)\n",
    "from statsmodels.stats import weightstats as ws\n",
    "ws.ztest(x1 = d3.loc[(d3['author_sex'] == 'male') & (d3['author_exp'] == 'newbie'),'rating_count'],\n",
    "         x2 = d3.loc[(d3['author_sex'] == 'male') & (d3['author_exp'] == 'experienced'),'rating_count'],\n",
    "         value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "090efcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.413302258270755, 6.187291596702804e-08)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Male (Average v/s Experienced)\n",
    "from statsmodels.stats import weightstats as ws\n",
    "ws.ztest(x1 = d3.loc[(d3['author_sex'] == 'male') & (d3['author_exp'] == 'average'),'rating_count'],\n",
    "         x2 = d3.loc[(d3['author_sex'] == 'male') & (d3['author_exp'] == 'experienced'),'rating_count'],\n",
    "         value = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2072c27b",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8401c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0663869925052734, 0.2862487392291887)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Female (Newbie v/s Average)\n",
    "from statsmodels.stats import weightstats as ws\n",
    "ws.ztest(x1 = d3.loc[(d3['author_sex'] == 'female') & (d3['author_exp'] == 'newbie'),'rating_count'],\n",
    "         x2 = d3.loc[(d3['author_sex'] == 'female') & (d3['author_exp'] == 'average'),'rating_count'],\n",
    "         value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d4d39b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.3597119117780965, 0.018289131843670016)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Female (Newbie v/s Experienced)\n",
    "from statsmodels.stats import weightstats as ws\n",
    "ws.ztest(x1 = d3.loc[(d3['author_sex'] == 'female') & (d3['author_exp'] == 'newbie'),'rating_count'],\n",
    "         x2 = d3.loc[(d3['author_sex'] == 'female') & (d3['author_exp'] == 'experienced'),'rating_count'],\n",
    "         value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf7afeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.941984966492798, 8.081004281510416e-05)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Female (Average v/s Experienced)\n",
    "from statsmodels.stats import weightstats as ws\n",
    "ws.ztest(x1 = d3.loc[(d3['author_sex'] == 'female') & (d3['author_exp'] == 'average'),'rating_count'],\n",
    "         x2 = d3.loc[(d3['author_sex'] == 'female') & (d3['author_exp'] == 'experienced'),'rating_count'],\n",
    "         value = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138d5dac",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32407ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5514378076087788, 0.5813335891758067)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Newbie (Male v/s Female)\n",
    "from statsmodels.stats import weightstats as ws\n",
    "ws.ztest(x1 = d3.loc[(d3['author_sex'] == 'male') & (d3['author_exp'] == 'newbie'),'rating_count'],\n",
    "         x2 = d3.loc[(d3['author_sex'] == 'female') & (d3['author_exp'] == 'newbie'),'rating_count'],\n",
    "         value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cfd2220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.17127906652047378, 0.8640043397253947)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average (Male v/s Female)\n",
    "from statsmodels.stats import weightstats as ws\n",
    "ws.ztest(x1 = d3.loc[(d3['author_sex'] == 'male') & (d3['author_exp'] == 'average'),'rating_count'],\n",
    "         x2 = d3.loc[(d3['author_sex'] == 'female') & (d3['author_exp'] == 'average'),'rating_count'],\n",
    "         value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2eef6706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.9477706728153442, 0.34324621356225427)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experienced (Male v/s Female)\n",
    "from statsmodels.stats import weightstats as ws\n",
    "ws.ztest(x1 = d3.loc[(d3['author_sex'] == 'male') & (d3['author_exp'] == 'experienced'),'rating_count'],\n",
    "         x2 = d3.loc[(d3['author_sex'] == 'female') & (d3['author_exp'] == 'experienced'),'rating_count'],\n",
    "         value = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e6e8a2",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37384bcf",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9e2cea",
   "metadata": {},
   "source": [
    "#### Hypothesis 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3b7fbf",
   "metadata": {},
   "source": [
    "The publisher receives books with pages ranging from 1-10K+! Bulky books require a lot of time to be reviewed. And if they do not sell more, it’s just a waste of effort. The publisher is interested to see if the bulkier books have less rating count on an average as compared to average-sized books.  <br></br>\n",
    "Books can be classified into 3 bins: <br></br>\n",
    "- Light: <80 pages (or <2 std. Dev from mean) \n",
    "- Average: within 1 std. Dev from mean page count (both sides)\n",
    "- Bulky: > 1 std. Dev from mean page count\n",
    "\n",
    "<center> Null Hypothesis: Average rating count of a bulky book is greater than or equal to that of an average size book. </center>\n",
    "\n",
    "Test: <br></br>\n",
    "Independent 1-tailed Z-test to compare mean rating count b/w Bulky  and Average sized books.\n",
    "\n",
    "Outcome: <br></br>\n",
    "p-value of the sample under Null Hypothesis <br></br>\n",
    "Considering 5% level of significance,  if the p-value would be less than 5%, then we would reject the null hypothesis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b404639f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.046462467727214, 7.40303518575635e-10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bulky v/s Average\n",
    "from statsmodels.stats import weightstats as ws\n",
    "ws.ztest(x1 = data.loc[data['book_size'] == 'bulky','rating_count'],\n",
    "         x2 = data.loc[data['book_size'] == 'average','rating_count'],\n",
    "         value = 0, alternative = 'larger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6173f7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.1090357422401165, 0.9990615049482333)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Light v/s Average\n",
    "from statsmodels.stats import weightstats as ws\n",
    "ws.ztest(x1 = data.loc[data['book_size'] == 'light','rating_count'],\n",
    "         x2 = data.loc[data['book_size'] == 'average','rating_count'],\n",
    "         value = 0, alternative = 'larger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cde5c1c",
   "metadata": {},
   "source": [
    "#### Hypothesis 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760fe02d",
   "metadata": {},
   "source": [
    "Genre of the book is an obvious factor that can have a grossing affect on the rating count. The most popular ones being: Fiction and Non-Fiction (we’ll club the rest in ‘others’). Intuitively, most people prefer reading fiction over non-fiction and others. The publisher is interested to know if this is indeed true. If we find out that the rating count of fiction is not greater than non-fiction (or others), then we would know that the bias a publisher has toward fiction books is ill-formed.\n",
    "\n",
    "<center> Null Hypothesis: Average rating count of Fiction books is greater than or equal to that of non-fiction & others. </center>\n",
    "\n",
    "Test: <br></br>\n",
    "2 Pairwise comparison of means b/w group 1 v/s 2, and group 1 v/s 3\n",
    "\t\n",
    "Outcome: <br></br>\n",
    "p-value of the sample under Null Hypothesis in both tests <br></br>\n",
    "Considering 5% level of significance,  if the p-value would be less than 5%, then we would reject the null hypothesis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f729bf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.138707626988176, 1.38317211447273e-07)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fiction v/s Non-Fiction\n",
    "from statsmodels.stats import weightstats as ws\n",
    "ws.ztest(x1 = data.loc[data['genre_category'] == 'fiction','rating_count'],\n",
    "         x2 = data.loc[data['genre_category'] == 'non-fiction','rating_count'],\n",
    "         value = 0, alternative = 'larger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56a69680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.841139078088977, 3.742921234655322e-23)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fiction v/s Others\n",
    "from statsmodels.stats import weightstats as ws\n",
    "ws.ztest(x1 = data.loc[data['genre_category'] == 'fiction','rating_count'],\n",
    "         x2 = data.loc[data['genre_category'] == 'others','rating_count'],\n",
    "         value = 0, alternative = 'larger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9f127fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.597470935849239, 2.138251304452644e-06)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fiction v/s Others\n",
    "from statsmodels.stats import weightstats as ws\n",
    "ws.ztest(x1 = data.loc[data['genre_category'] == 'non-fiction','rating_count'],\n",
    "         x2 = data.loc[data['genre_category'] == 'others','rating_count'],\n",
    "         value = 0, alternative = 'larger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1971d31",
   "metadata": {},
   "source": [
    "#### Grouping Hypothesis 3 & 4: Bulkier books may have a different selling pattern across fiction & non-fiction genres. We also want to club Hypothesis 3 & 4 and check the effect of book genre & size on average rating count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d662939f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.811571012432866, 6.904318644528193e-05)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bulky (Fiction v/s Non-fiction)\n",
    "from statsmodels.stats import weightstats as ws\n",
    "ws.ztest(x1 = data.loc[(data['book_size'] == 'bulky') & (data['genre_category'] == 'fiction'),'rating_count'],\n",
    "         x2 = data.loc[(data['book_size'] == 'bulky') & (data['genre_category'] == 'non-fiction'),'rating_count'],\n",
    "         value = 0, alternative = 'larger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0447e6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.515402167995858, 1.7399163947011153e-08)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fiction (Bulky v/s Average)\n",
    "from statsmodels.stats import weightstats as ws\n",
    "ws.ztest(x1 = data.loc[(data['book_size'] == 'bulky') & (data['genre_category'] == 'fiction'),'rating_count'],\n",
    "         x2 = data.loc[(data['book_size'] == 'average') & (data['genre_category'] == 'fiction'),'rating_count'],\n",
    "         value = 0, alternative = 'larger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d794c681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.6092140276178453, 0.5423825835260467)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-Fiction (Bulky v/s Average)\n",
    "from statsmodels.stats import weightstats as ws\n",
    "ws.ztest(x1 = data.loc[(data['book_size'] == 'bulky') & (data['genre_category'] == 'non-fiction'),'rating_count'],\n",
    "         x2 = data.loc[(data['book_size'] == 'average') & (data['genre_category'] == 'non-fiction'),'rating_count'],\n",
    "         value = 0, alternative = 'two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2780ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd99a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162cbbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
